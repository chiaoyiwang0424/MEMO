<!DOCTYPE html>
<html>
  <head>
    <title>GitHub Pages Site for MEMO</title>
	<link rel="stylesheet" type="text/css" href="styles.css">
  </head>
  <body>
    <div class="titleauthor">
      <h1>MEMO: A Multimodal EMA and OCTA Retinal Image Dataset</h1><br>
      <p class="darkblue">Chiao-Yi Wang, Faranguisse Kakhi Sadrieh, Yi-Ting Shen, Shih-En Chen, Sarah Kim,</p>
	  <p class="darkblue">Victoria Chen, Achyut Raghavendra, Dongyi Wang, Osamah Saeedi, and Yang Tao</p>
	  <p class="green">University of Maryland (College Park) and University of Marylad (Baltimore)</p><br>
	</div>
	
	<div class="content">
	  <p>The MEMO dataset is established for the development and evaluation of multimodal retinal image registration with both large vessel segmentation ground truth and registration ground turth.</p>
	  <h2>Dataset Description</h2>
	  <p>The MEMO dataset contains 30 pairs of EMA and OCTA images. For each image pair, 6 corresponding point pairs were manually annotated. In addition, each EMA image comes with a carefully annotated vessel segmentation mask.</p>
	  <p>The following raw images are included for each image pair:</p>
	  <ul>
		<li>An EMA stacked image (Folder path: /MEMO/Original EMA stack)</li>
		<li>A folder for EMA sequence images (Under preparation)</li>
		<li>A folder for three OCTA projection images, including SVP, ICP and DCP layer projection images (Folder path: /MEMO/Original OCTA)</li>
	  </ul>
	  <p>For our own experiments, we scaled all OCTA SVP images to 256 * 256 and the EMA stacked images were scaled based on same sclaing factor. Therefore, we also provide the following scaled images:</p>
	  <ul>
		<li>Scaled EMA stacked image (Folder path: /MEMO/Scaled EMA stack)</li>
		<li>Scaled OCTA SVP image (Folder path: /MEMO/Scaled OCTA SVP)</li>
		<li>A vessel segmentation mask of EMA image (Folder path: /MEMO/Scaled EMA stack seg ground truth)</li>
		<!--<li>A large vessel segmentation mask of OCTA image (Folder path: /MEMO/Scaled OCTA SVP lv seg ground truth)</li>-->
	  </ul>
	  <p> Six corresponding point pairs of every EMA and OCTA pair are provided in <em>RegistrationGT.csv</em>. In this file, the pixel coordinate (x and y) of corresponding point pairs are listed. For example, the pixel coordinate (OCTA_x1, OCTA_y1) on OCTA image is matched to the pixel coordinate (EMA_x1, EMA_y1) on EMA stacked image. All the pixel coordinate are based on the scaled images.</p>.
	  <p class="img"><img src="Dataset_fig.jpg" alt="Dataset example figure" style="width:800px;height:218px;"/></p><br>
	  <h2>Dataset Download:</h2>
	  <p><a href="https://drive.google.com/drive/folders/1SJHjluoPo9HKqYSZlc2T6c6tHPNpGkAB?usp=share_link" target="_blank">MEMO Dataset</a>
	  <h2>Paper:</h2>
	  <p><a href="https://arxiv.org/abs/2309.14550" target="_blank">MEMO: Dataset and Methods for Robust Multimodal Retinal Image Registration with Large or Small Vessel Density Differences</a>
	  <h2>Citation:</h2>
	  <p>If you use this dataset for your research, please cite our paper.</p>
	  <p>@misc{wang2023memo,
      title={MEMO: Dataset and Methods for Robust Multimodal Retinal Image Registration with Large or Small Vessel Density Differences}, 
      author={Chiao-Yi Wang and Faranguisse Kakhi Sadrieh and Yi-Ting Shen and Shih-En Chen and Sarah Kim and Victoria Chen and Achyut Raghavendra and Dongyi Wang and Osamah Saeedi and Yang Tao},
      year={2023},
      eprint={2309.14550},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
      }</p>
	  <h2>Contact Info:</h2>
	  <p>Chiao-Yi Wang (cyiwang@umd.edu)</p>
	  
	</div>
  </body>
</html>